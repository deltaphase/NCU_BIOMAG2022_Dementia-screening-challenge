{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d82983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import emd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Helper function for the second level sift\n",
    "def mask_sift_second_layer(IA, masks, config={}):\n",
    "    imf2 = np.zeros((IA.shape[0], IA.shape[1], config['max_imfs']))\n",
    "    for ii in range(IA.shape[1]):\n",
    "        config['mask_freqs'] = masks[ii:]\n",
    "        tmp = emd.sift.mask_sift(IA[:, ii], **config)\n",
    "        imf2[:, ii, :tmp.shape[1]] = tmp\n",
    "    return imf2\n",
    "\n",
    "def get_holo_trl(filename, sys_type):\n",
    "    raw=mne.io.read_raw_fif(filename)\n",
    "\n",
    "    if sys_type == 'A':\n",
    "        ag_num = [13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 46, 48, 56, 57, 58, 60, 61, 62, 63, 64, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 110, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "    if sys_type == 'B':\n",
    "        ag_num = [9, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29, 30, 31, 33, 34, 49, 50, 58, 59, 60, 61, 62, 63, 64, 76, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 110, 114, 121, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "    ag_names = ['AG%.3d'%s for s in ag_num]\n",
    "    ag_picks = mne.pick_channels(raw.ch_names, ag_names)\n",
    "\n",
    "    # find alpha\n",
    "    freqs_sig = 9, 12\n",
    "    freqs_noise = 8, 13\n",
    "\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=2, preload=False)\n",
    "    epochs.drop_bad(reject = dict(mag=3e-12))      # unit: T (magnetometers)\n",
    "\n",
    "    ssd = SSD(info=raw.info,\n",
    "              reg='oas',\n",
    "              sort_by_spectral_ratio=False,  # False for purpose of example.\n",
    "              n_components = 5,\n",
    "              picks = ag_picks,\n",
    "              filt_params_signal=dict(l_freq=freqs_sig[0], h_freq=freqs_sig[1],\n",
    "                                      l_trans_bandwidth=1, h_trans_bandwidth=1),\n",
    "              filt_params_noise=dict(l_freq=freqs_noise[0], h_freq=freqs_noise[1],\n",
    "                                     l_trans_bandwidth=1, h_trans_bandwidth=1))\n",
    "    ssd.fit(X=epochs.get_data())\n",
    "\n",
    "    pattern = mne.EvokedArray(data=ssd.patterns_[:4].T,\n",
    "                              info=ssd.info)\n",
    "    pattern.plot_topomap(units=dict(mag='A.U.'), time_format='')\n",
    "\n",
    "    idx = np.argmax(np.abs(ssd.patterns_[0]))\n",
    "    name_ = raw.info['ch_names'][idx]\n",
    "    epochs.load_data()\n",
    "    x = epochs.copy().pick_channels([name_]).get_data()\n",
    "    x = np.squeeze(x) * 1e+15\n",
    "    x.shape\n",
    "\n",
    "    n_trl = epochs.get_data().shape[0]\n",
    "    sholo_temp = np.zeros((n_trl, 256, 128))\n",
    "\n",
    "    sample_rate = np.int(raw.info['sfreq'])\n",
    "    config = emd.sift.get_config('mask_sift')\n",
    "    config['max_imfs'] = 7\n",
    "    config['mask_freqs'] = 50/sample_rate\n",
    "    config['mask_amp_mode'] = 'ratio_sig'\n",
    "    config['imf_opts/sd_thresh'] = 0.05\n",
    "\n",
    "    # Carrier frequency histogram definition\n",
    "    carrier_hist = (1, 100, 256, 'log')\n",
    "    # AM frequency histogram definition\n",
    "    am_hist = (1e-2, 32, 128, 'log')\n",
    "\n",
    "    for n in range(n_trl):\n",
    "        imf = emd.sift.mask_sift(x[n], **config)\n",
    "        IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "        masks = np.array([25/2**ii for ii in range(12)])/sample_rate\n",
    "        config = emd.sift.get_config('mask_sift')\n",
    "        config['mask_amp_mode'] = 'ratio_sig'\n",
    "        config['mask_amp'] = 2\n",
    "        config['max_imfs'] = 5\n",
    "        config['imf_opts/sd_thresh'] = 0.05\n",
    "        config['envelope_opts/interp_method'] = 'mono_pchip'\n",
    "\n",
    "        # Sift the first 5 first level IMFs\n",
    "        imf2 = emd.sift.mask_sift_second_layer(IA, masks, sift_args=config)\n",
    "\n",
    "        IP2, IF2, IA2 = emd.spectra.frequency_transform(imf2, sample_rate, 'nht')\n",
    "        fcarrier, fam, holo = emd.spectra.holospectrum(IF[:,0:6], IF2[:,0:6,:], IA2[:,0:6,:], carrier_hist, am_hist)\n",
    "        sholo = ndimage.gaussian_filter(holo, 1)\n",
    "\n",
    "        sholo_temp[n] = sholo\n",
    "        pass\n",
    "\n",
    "    sholo_m = np.squeeze(np.nanmean(sholo_temp, axis = 0))\n",
    "    return sholo_m, fam, fcarrier\n",
    "\n",
    "\n",
    "def get_psd_median(s, group, sys_type):\n",
    "    filename = 'de_hokuto_%s%d-raw.fif'%(group, s)\n",
    "    raw=mne.io.read_raw_fif(filename)\n",
    "\n",
    "    if sys_type == 'A':\n",
    "        ag_num = [13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 46, 48, 56, 57, 58, 60, 61, 62, 63, 64, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 110, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "    if sys_type == 'B':\n",
    "        ag_num = [9, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29, 30, 31, 33, 34, 49, 50, 58, 59, 60, 61, 62, 63, 64, 76, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 110, 114, 121, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "    ag_names = ['AG%.3d'%s for s in ag_num]\n",
    "    ag_picks = mne.pick_channels(raw.ch_names, ag_names)\n",
    "\n",
    "    raw.pick(ag_picks)\n",
    "\n",
    "\n",
    "\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=2, preload=False)\n",
    "    epochs.drop_bad(reject = dict(mag=3e-12))      # unit: pT (magnetometers)\n",
    "    psd, freq_ = mne.time_frequency.psd_array_welch(epochs.get_data() * 1e+15, \n",
    "                                                    epochs.info['sfreq'], \n",
    "                                                    fmin=0, fmax=40, \n",
    "                                                    n_fft=256, average='mean')\n",
    "\n",
    "    psd_M=np.expand_dims(psd[0].mean(axis = 1),axis=1)\n",
    "    psd_evk=mne.EvokedArray(psd_M,epochs.info,comment='raw_data')\n",
    "    #psd_evk.plot_topomap(times=0,ch_type='mag',scalings=dict(mag=1), extrapolate='head',sensors=False, contours=0)\n",
    "    psd_median = np.sqrt(np.squeeze(np.median(psd.mean(axis=0), axis=0)))\n",
    "    psd_mean = np.sqrt(np.squeeze(np.mean(psd.mean(axis=0), axis=0)))\n",
    "    #plt.plot(freq_, psd_median, 'r', freq_, psd_mean, 'b')\n",
    "    return  freq_, psd_median, psd_mean\n",
    "\n",
    "\n",
    "def get_hht_median(s, group, sys_type):\n",
    "    filename = 'de_hokuto_%s%d-raw.fif'%(group, s)\n",
    "    raw=mne.io.read_raw_fif(filename)\n",
    "\n",
    "    if sys_type == 'A':\n",
    "        ag_num = [13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 46, 48, 56, 57, 58, 60, 61, 62, 63, 64, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 110, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "    if sys_type == 'B':\n",
    "        ag_num = [9, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29, 30, 31, 33, 34, 49, 50, 58, 59, 60, 61, 62, 63, 64, 76, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 110, 114, 121, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "    ag_names = ['AG%.3d'%s for s in ag_num]\n",
    "    ag_picks = mne.pick_channels(raw.ch_names, ag_names)\n",
    "\n",
    "    raw.pick(ag_picks)\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=2, preload=False)\n",
    "    epochs.drop_bad(reject = dict(mag=3e-12))      # unit: pT (magnetometers)\n",
    "\n",
    "    x = epochs.get_data() * 1e+15\n",
    "    n_trl, nch, nTime = x.shape\n",
    "    n_imf = 6\n",
    "\n",
    "    IMF_temp = np.zeros((n_trl, nch, nTime, n_imf))\n",
    "    IF_temp = np.zeros((n_trl, nch, nTime, n_imf))\n",
    "    IA_temp = np.zeros((n_trl, nch, nTime, n_imf))\n",
    "    IP_temp = np.zeros((n_trl, nch, nTime, n_imf))\n",
    "    hht_temp = np.zeros((n_trl, nch, 64))\n",
    "    sample_rate = np.int(raw.info['sfreq'])\n",
    "\n",
    "    # Carrier frequency histogram definition\n",
    "    carrier_hist = (1, 32, 64, 'log')\n",
    "    # AM frequency histogram definition\n",
    "    am_hist = (1e-2, 32, 128, 'log')\n",
    "\n",
    "    config = emd.sift.get_config('mask_sift')\n",
    "    config['max_imfs'] = n_imf\n",
    "    config['mask_freqs'] = 50/sample_rate\n",
    "    config['mask_amp_mode'] = 'ratio_sig'\n",
    "    config['imf_opts/sd_thresh'] = 0.05\n",
    "    config['verbose'] = 'CRITICAL'\n",
    "\n",
    "    for n in range(n_trl):\n",
    "        for c in range(nch):\n",
    "            imf = emd.sift.mask_sift(np.squeeze(x[n, c,:]), **config)\n",
    "            IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "            freq_, hht = emd.spectra.hilberthuang(IF_temp[0][0], IA_temp[0][0], carrier_hist, scaling='density', sample_rate=500, sum_imfs=True)\n",
    "            IMF_temp[n, c, :, :] = imf\n",
    "            IF_temp[n, c, :, :] = IF\n",
    "            IA_temp[n, c, :, :] = IA\n",
    "            IP_temp[n, c, :, :] = IP\n",
    "            hht_temp[n, c, :] = hht\n",
    "\n",
    "    hht_median = np.sqrt(np.squeeze(np.median(hht_temp.mean(axis=0), axis=0)))\n",
    "    hht_mean = np.sqrt(np.squeeze(np.mean(hht_temp.mean(axis=0), axis=0)))\n",
    "    #plt.plot(freq_, psd_median, 'r', freq_, psd_mean, 'b')\n",
    "    return  freq_, hht_median, hht_mean, IF_temp, IP_temp, IMF_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9508d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8df37",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group = 'control'\n",
    "\n",
    "\n",
    "sys_types = ['A','B','A','A','A','A','A','B','B','B','A',\n",
    "             'A','A','B','A','A','B','B','B','B','A','A','B','A','A','A','A',\n",
    "             'A','A','A','B','B','A','A','B','A','A','A','A','B','A','A','A',\n",
    "             'A','A','A','A','A','B','A','A','A','A','A','A','A','B','A','A',\n",
    "             'A','A','A','A','A','A','A','A','A','A','A','A','A','A','A','A',\n",
    "             'A','B','B','B','A','A','A','A','A','A','A','A','B','A','B','A',\n",
    "             'A','A','B','B','B','B','A','B','B']\n",
    "\n",
    "excluded_control = []\n",
    "\n",
    "hht_median_c = []\n",
    "hht_mean_c = []\n",
    "for i in range(100):\n",
    "    s = i + 1\n",
    "    sys_type = sys_types[i]\n",
    "    print(s)\n",
    "    try:\n",
    "        freq_, hht_median, hht_mean, IF_temp, IP_temp, IMF_temp = get_hht_median(s, group, sys_type)\n",
    "        hht_median_c.append(hht_median)\n",
    "        hht_mean_c.append(hht_mean)\n",
    "    except:\n",
    "        print('no id %d'%s)\n",
    "        excluded_control.append(s)\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f79033",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "group = 'dementia'\n",
    "\n",
    "\n",
    "sys_types = ['A','B','A','B','A','B','B','B','B',\n",
    "             'A','B','A','A','A','A','A','A','A',\n",
    "             'A','B','A','B','A','A','B','A','A',\n",
    "             'A','A']\n",
    "excluded_dementia = []\n",
    "hht_median_d = []\n",
    "hht_mean_d = []\n",
    "for i in range(29):\n",
    "    s = i + 1\n",
    "    sys_type = sys_types[i]\n",
    "    try:\n",
    "        freq_, hht_median, hht_mean, IF_temp, IP_temp, IMF_temp = get_hht_median(s, group, sys_type)\n",
    "        hht_median_d.append(hht_median)\n",
    "        hht_mean_d.append(hht_mean)\n",
    "    except:\n",
    "        print('no id %d'%s)\n",
    "        excluded_dementia.append(s)\n",
    "    pass\n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "group = 'mci'\n",
    "\n",
    "\n",
    "sys_types = ['B','B','B','B','B','B','B','B','B',\n",
    "             'B','A','B','B','B','B']\n",
    "excluded_mci = []\n",
    "hht_median_m = []\n",
    "hht_mean_m = []\n",
    "for i in range(15):\n",
    "    s = i + 1\n",
    "    sys_type = sys_types[i]\n",
    "    try:\n",
    "        freq_, hht_median, hht_mean, IF_temp, IP_temp, IMF_temp = get_hht_median(s, group, sys_type)\n",
    "        hht_median_m.append(hht_median)\n",
    "        hht_mean_m.append(hht_mean)\n",
    "    except:\n",
    "        print('no id %d'%s)\n",
    "        excluded_mci.append(s)\n",
    "    pass\n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(excluded_control)\n",
    "print(excluded_dementia)\n",
    "print(excluded_mci)\n",
    "psd_mdn_d = np.vstack(psd_median_d)\n",
    "psd_mdn_c = np.vstack(psd_median_c)\n",
    "psd_mdn_m = np.vstack(psd_median_m)\n",
    "\n",
    "psd_m_d = np.vstack(psd_mean_d)\n",
    "psd_m_c = np.vstack(psd_mean_c)\n",
    "psd_m_m = np.vstack(psd_mean_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_mdn = np.concatenate((psd_mdn_c, psd_mdn_d, psd_mdn_m),axis=0)\n",
    "psd_m = np.concatenate((psd_m_c, psd_m_d, psd_m_m),axis=0)\n",
    "\n",
    "y = [0] * psd_mdn_c.shape[0] + [1] * psd_mdn_d.shape[0] + [2] * psd_mdn_m.shape[0]\n",
    "y = np.array(y)\n",
    "print(psd_m.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59908cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "wclf = svm.SVC(kernel=\"linear\", class_weight={0: 1, 1: 10, 2:1})\n",
    "\n",
    "scores = cross_val_score(wclf, psd_mdn, y, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(wclf, psd_mdn, y, cv=10, return_train_score=True)\n",
    "print(scores['train_score'].mean())\n",
    "print(scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6ca46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(wclf, psd_m, y, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((psd_mdn, psd_m), axis=1)\n",
    "scores = cross_val_score(wclf, X, y, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "clf = MLPClassifier(solver='adam', learning_rate_init=0.001, max_iter=10000, random_state=1)\n",
    "\n",
    "#X = MinMaxScaler().fit_transform(psd_mdn)\n",
    "X = psd_mdn\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    clf.fit(X[train_indices], y[train_indices])\n",
    "    print(clf.score(X[test_indices], y[test_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = psd_mdn\n",
    "\n",
    "clf = MLPClassifier(solver='adam', learning_rate_init=0.001, max_iter=10000, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeeecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'test'\n",
    "\n",
    "sys_types = ['A','A','B','B','A','B','A','B','A',\n",
    "             'A','B','A','A','A','A','B','B','A',\n",
    "             'A','A','B','B','B','B','B','B','B',\n",
    "             'B','B','B','A','A','B','B','A','A',\n",
    "             'A','A','A','A','A','B']\n",
    "\n",
    "excluded_test = []\n",
    "psd_median_t = []\n",
    "psd_mean_t = []\n",
    "for i in range(42):\n",
    "    s = i + 1\n",
    "    sys_type = sys_types[i]\n",
    "    try:\n",
    "        freq_, psd_median, psd_mean = get_psd_median(s, group, sys_type)\n",
    "        psd_median_t.append(psd_median)\n",
    "        psd_mean_t.append(psd_mean)\n",
    "    except:\n",
    "        print('no id %d'%s)\n",
    "        excluded_test.append(s)\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99160dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(psd_median_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74756df",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(psd_median_t).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'de_hokuto_%s%d-raw.fif'%('test', 16)\n",
    "raw=mne.io.read_raw_fif(filename)\n",
    "\n",
    "sys_type = 'B'\n",
    "\n",
    "if sys_type == 'A':\n",
    "    ag_num = [13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 46, 48, 56, 57, 58, 60, 61, 62, 63, 64, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 110, 112, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "if sys_type == 'B':\n",
    "    ag_num = [9, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29, 30, 31, 33, 34, 49, 50, 58, 59, 60, 61, 62, 63, 64, 76, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 110, 114, 121, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
    "\n",
    "ag_names = ['AG%.3d'%s for s in ag_num]\n",
    "ag_picks = mne.pick_channels(raw.ch_names, ag_names)\n",
    "\n",
    "raw.pick(ag_picks)\n",
    "\n",
    "\n",
    "\n",
    "epochs = mne.make_fixed_length_epochs(raw, duration=2, preload=False)\n",
    "epochs.drop_bad(reject = dict(mag=5e-12))      # unit: pT (magnetometers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info['bads'])\n",
    "raw.drop_channels(raw.info['bads'])\n",
    "\n",
    "epochs = mne.make_fixed_length_epochs(raw, duration=2, preload=False)\n",
    "epochs.drop_bad(reject = dict(mag=3e-12))      # unit: pT (magnetometers)\n",
    "psd, freq_ = mne.time_frequency.psd_array_welch(epochs.get_data() * 1e+15, \n",
    "                                                epochs.info['sfreq'], \n",
    "                                                fmin=0, fmax=40, \n",
    "                                                n_fft=256, average='mean')\n",
    "\n",
    "psd_M=np.expand_dims(psd[0].mean(axis = 1),axis=1)\n",
    "psd_evk=mne.EvokedArray(psd_M,epochs.info,comment='raw_data')\n",
    "psd_evk.plot_topomap(times=0,ch_type='mag',scalings=dict(mag=1), extrapolate='head',sensors=False, contours=0)\n",
    "psd_median_1 = np.sqrt(np.squeeze(np.median(psd.mean(axis=0), axis=0)))\n",
    "\n",
    "print(clf.predict([psd_median_1]))\n",
    "print(clf.predict_proba([psd_median_1]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e92636",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_evk.plot_topomap(times=0,ch_type='mag',scalings=dict(mag=1), extrapolate='head',sensors=True, contours=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_evk.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34201ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
